# Cansado de respostas vagas da IA ao pedir documentaÃ§Ã£o ou comparaÃ§Ãµes tÃ©cnicas?

Compartilhando mais um aprendizado da minha jornada de *"Learning in Public"* no MBA em Engenharia de Software com IA.

Descobri que a chave para respostas melhores nÃ£o estÃ¡ apenas no que vocÃª pergunta, mas em como vocÃª guia o modelo a pensar: Ã© aqui que entra a tÃ©cnica de **"Directed Prompting"** (ou EstÃ­mulo Direcional).

Aqui estÃ£o 3 formas como essa tÃ©cnica muda o jogo para nÃ³s, engenheiros de software:

* **ğŸš€ Controle e PadronizaÃ§Ã£o:**
    * O Directed Prompting reduz a ambiguidade e o risco de alucinaÃ§Ãµes, forÃ§ando o modelo a seguir um formato consistente.
    * *A PrÃ¡tica:* Ideal para gerar documentaÃ§Ã£o tÃ©cnica usando comandos explÃ­citos como *'Divida em tÃ³picos: contexto, estratÃ©gia, riscos...'*

* **ğŸ’¡ SaÃ­das Prontas para AutomaÃ§Ã£o:**
    * Ao instruir o modelo a responder em formatos como **JSON** ou **YAML**, melhoramos a "utilidade programÃ¡tica" da saÃ­da.
    * *O Ganho:* A resposta pode ser consumida diretamente por scripts e pipelines CI/CD, eliminando o trabalho manual de *parsing*.

* **ğŸ¤– SimulaÃ§Ã£o de Especialistas:**
    * Comandos como *'Explique como um arquiteto sÃªnior faria...'* ou *'Justifique cada item...'* condicionam o modelo a adotar um estilo de raciocÃ­nio profundo.
    * *Exemplo:* Comparar Kafka vs. RabbitMQ descrevendo fluxos distribuÃ­dos com o nÃ­vel de detalhe de um especialista.

Para ver essa tÃ©cnica em aÃ§Ã£o e entender o fluxo completo, confira o infogrÃ¡fico abaixo! ğŸ‘‡

E vocÃª, jÃ¡ usa alguma tÃ©cnica especÃ­fica de prompt para otimizar seu trabalho? Compartilhe nos comentÃ¡rios!

#EngenhariaDeSoftware #AI #PromptEngineering #MBA #LLM
